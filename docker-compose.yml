  # O Data Warehouse (destino dos dados do pipeline).
  dwh_postgres:
    image: postgres:16
    container_name: banvic_dwh_db
    environment:
      POSTGRES_DB: banvic_dwh
      POSTGRES_USER: dwh_user
      POSTGRES_PASSWORD: dwh_password
    volumes:
      - ./dwhdata:/var/lib/postgresql/data
    ports:
      # A porta 5433 para evitar possíveis conflitos com a porta 5432 usada pelo banco de origem.
      - "5433:5432"

  # Serviço do banco de dados para os metadados internos do Airflow.
  postgres-airflow:
    image: postgres:16
    container_name: airflow_postgres_db
    environment:
      POSTGRES_DB: airflow_metadata
      POSTGRES_USER: airflow_user
      POSTGRES_PASSWORD: airflow_password
    volumes:
      - ./airflow_metadata:/var/lib/postgresql/data
    # O 'healthcheck' verifica se o contêiner está pronto para ser usado.
    healthcheck:
      # Comando para verificar se o banco de dados está pronto para aceitar conexões.
      test: ["CMD-SHELL", "pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}"]
      # Intervalo de 5 segundos entre as verificações.
      interval: 5s
      
      timeout: 5s
      # Número de tentativas antes de considerar o serviço como 'não saudável'.
      retries: 5

  # Serviço para inicializar o Airflow.
  airflow-init:
    image: apache/airflow:2.9.2
    container_name: airflow_init
    # 'depends_on' garante que o 'postgres-airflow' esteja pronto antes de iniciar.
    depends_on:
      postgres-airflow:
        condition: service_healthy
    environment:
      # Define o diretório de trabalho do Airflow.
      AIRFLOW_HOME: /opt/airflow
      # String de conexão para o banco de dados de metadados do Airflow.
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow_user:airflow_password@postgres-airflow:5432/airflow_metadata
    volumes:
      # Mapeia a pasta local 'dags' para o diretório de DAGs do contêiner.
      - ./dags:/opt/airflow/dags
    # O comando 'bash -c' executa uma sequência de comandos.
    command: >
      bash -c "
      # Inicializa o banco de dados do Airflow.
      airflow db migrate &&
      # Cria o usuário 'admin' para a interface do Airflow.
      airflow users create --username airflow --password airflow --firstname Joao --lastname Castro --role Admin --email joao@example.com
      "

  # Serviço do webserver do Airflow (Interface de usuário).
  airflow-webserver:
    image: apache/airflow:2.9.2
    container_name: airflow_webserver
    # Reinicia o contêiner automaticamente se ele parar.
    restart: always
    # Garante que os serviços de inicialização e DWH estejam prontos.
    depends_on:
      - airflow-init
      - dwh_postgres
    environment:
      AIRFLOW_HOME: /opt/airflow
      # Define o tipo de executor, 'LocalExecutor' para um ambiente de desenvolvimento.
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow_user:airflow_password@postgres-airflow:5432/airflow_metadata
      # Chave secreta para segurança da interface web.
      AIRFLOW__WEBSERVER__SECRET_KEY: "chavesupersecreta"
    # Mapeamento de volumes para que o webserver acesse DAGs, logs e dados.
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./data:/opt/airflow/data
    ports:
      # Mapeia a porta 8080 do seu computador para a porta 8080 do contêiner.
      # Isso permite acessar a interface do Airflow no seu navegador.
      - "8080:8080"
    # Inicia o serviço do webserver.
    command: webserver
    # 'healthcheck' para verificar a saúde do webserver.
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 30s
      retries: 3

  # Serviço do scheduler do Airflow.
  # Ele agenda e executa as tarefas do DAG.
  airflow-scheduler:
    image: apache/airflow:2.9.2
    container_name: airflow_scheduler
    restart: always
    depends_on:
      - airflow-init
      - dwh_postgres
    environment:
      AIRFLOW_HOME: /opt/airflow
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow_user:airflow_password@postgres-airflow:5432/airflow_metadata
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./data:/opt/airflow/data
    # Inicia o serviço do scheduler.
    command: scheduler